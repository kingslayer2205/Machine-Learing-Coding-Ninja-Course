{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train ,x_test , y_train , y_test = train_test_split(iris.data , iris.target , random_state = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 1., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_data = np.loadtxt('xor.csv',delimiter = ',')\n",
    "or_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data , columns = ['sl','sw','pl','pw'])\n",
    "df['target'] = iris.target\n",
    "df_latest = iris.target_names[df.target]\n",
    "df.target = df_latest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw  target\n",
       "0  5.1  3.5  1.4  0.2  setosa\n",
       "1  4.9  3.0  1.4  0.2  setosa\n",
       "2  4.7  3.2  1.3  0.2  setosa\n",
       "3  4.6  3.1  1.5  0.2  setosa\n",
       "4  5.0  3.6  1.4  0.2  setosa"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df , test_size):\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices , k= test_size)\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df , test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df , test_df = train_test_split(df , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_node(data):\n",
    "    target = data[:,-1]\n",
    "    target = np.unique(target)\n",
    "    if(len(target) == 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    target = data[:,-1]\n",
    "    unique_class , count = np.unique(target , return_counts = True)\n",
    "    \n",
    "    index = count.argmax()\n",
    "    classificaion = unique_class[index]\n",
    "    \n",
    "    return classificaion\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_split(data):\n",
    "    split = {}\n",
    "    row, col = data.shape \n",
    "    for col_index in range(col -1):\n",
    "        split[col_index] = []\n",
    "        val = data[:,col_index]\n",
    "        unique_val = np.unique(val)\n",
    "        \n",
    "        for index in range(len(unique_val)):\n",
    "            if index!=0:\n",
    "                curr_val = unique_val[index]\n",
    "                prev_val = unique_val[index-1]\n",
    "                split_val = round((curr_val + prev_val)/2 , 2)\n",
    "                split[col_index].append(split_val)\n",
    "    return split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data , split_col , split_val):\n",
    "    split_col_val = data[:,split_col]\n",
    "    data_below = data[split_col_val <= split_val]\n",
    "    data_above = data[split_col_val > split_val]\n",
    "    \n",
    "    return data_below , data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_col = 3\n",
    "# split_val = 1.05\n",
    "# below , above = split_data(data , split_col , split_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting_df = pd.DataFrame(data , columns = df.columns)\n",
    "# sns.lmplot(data=plotting_df, x = \"pw\" , y =\"pl\", fit_reg = False)\n",
    "# plt.vlines(x=split_val ,ymin=1,ymax=7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    target = data[:,-1]\n",
    "    t , counts = np.unique(target , return_counts= True)\n",
    "    prob = counts / (counts.sum())\n",
    "    entropy = sum(prob * -np.log2(prob))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_entropy(above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_overall_entropy(data_below , data_above):\n",
    "    n_data_points = len(data_above) + len(data_below)\n",
    "    p_above = len(data_above) / n_data_points\n",
    "    p_below = len(data_below) / n_data_points\n",
    "\n",
    "    overall_entropy = (p_above * calculate_entropy(data_above)) + (p_below * calculate_entropy(data_below))\n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal_overall_entropy(below ,above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data , split):\n",
    "    overall_entropy = 10000\n",
    "    for col_index in split:\n",
    "        for val in split[col_index]:\n",
    "            data_below , data_above = split_data(data , col_index , val)\n",
    "            curr_overall_entropy = cal_overall_entropy(data_below , data_above)\n",
    "\n",
    "            if curr_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = curr_overall_entropy\n",
    "                best_split_col = col_index\n",
    "                best_split_val = val\n",
    "\n",
    "    return best_split_col,best_split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_split_info(data_below , data_above):\n",
    "    len_total = len(data_below) + len(data_above)\n",
    "    p_below = len(data_below) / len_total\n",
    "    p_above = len(data_above) / len_total\n",
    "    \n",
    "    split_info = (-p_below)* np.log2(p_below) + (-p_above)* np.log2(p_above)\n",
    "    \n",
    "    return split_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_using_gain_ratio(data , split):\n",
    "    info_gain = 0\n",
    "    \n",
    "    for col_index in split:\n",
    "        for val in split[col_index]:\n",
    "            data_below , data_above = split_data(data , col_index , val)\n",
    "            curr_overall_entropy = cal_overall_entropy(data_below , data_above)\n",
    "            root_entopy = calculate_entropy(data)\n",
    "            split_info = cal_split_info(data_below , data_above)\n",
    "            curr_info_gain = (root_entopy - curr_overall_entropy)/split_info\n",
    "#             print(curr_info_gain)\n",
    "            if info_gain <= curr_info_gain:\n",
    "                info_gain = curr_info_gain\n",
    "                best_split_col = col_index\n",
    "                best_split_val = val\n",
    "        \n",
    "    return best_split_col,best_split_val , info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_alogo(df,counter=0 , min_samples = 2 , max_depth =5):\n",
    "    \n",
    "    # data preparation\n",
    "    if counter == 0:\n",
    "        global col_header\n",
    "        col_header = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "    # base case\n",
    "    if (pure_node(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    # recursive part\n",
    "    else:\n",
    "        counter +=1\n",
    "        split = potential_split(data)\n",
    "        split_col , split_val,gain_ratio = find_best_split_using_gain_ratio(data ,split)\n",
    "        below , above = split_data(data,split_col , split_val)\n",
    "        t , counts = np.unique(data[:,-1] , return_counts= True) \n",
    "        # subtree\n",
    "        feature_name = col_header[split_col]\n",
    "        quen = \"{} <= {} , gain={} , samples={} ,value={} \".format( feature_name, split_val,\n",
    "                                                                round(gain_ratio,7),len(data),counts)\n",
    "        sub_tree = {quen :[]}\n",
    "        \n",
    "        #find answer\n",
    "        yes_ans = decision_tree_alogo(below,counter,min_samples,max_depth)\n",
    "        no_ans = decision_tree_alogo(above,counter,min_samples,max_depth)\n",
    "        if yes_ans == no_ans:\n",
    "            sub_tree = yes_ans\n",
    "        else:\n",
    "            sub_tree[quen].append(yes_ans)\n",
    "            sub_tree[quen].append(no_ans)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pw <= 0.8 , gain=1.0 , samples=130 ,value=[46 42 42] ': ['setosa', {'pw <= 1.65 , gain=0.7327835 , samples=84 ,value=[42 42] ': [{'pl <= 4.95 , gain=0.6492629 , samples=44 ,value=[41  3] ': ['versicolor', {'pw <= 1.55 , gain=1.0 , samples=4 ,value=[1 3] ': ['virginica', 'versicolor']}]}, {'pl <= 4.85 , gain=0.1866395 , samples=40 ,value=[ 1 39] ': [{'sw <= 3.1 , gain=1.0 , samples=4 ,value=[1 3] ': ['virginica', 'versicolor']}, 'virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree =decision_tree_alogo(train_df,max_depth = 5)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_steps(df,counter=0 , min_samples = 2 , max_depth =5):\n",
    "    \n",
    "    # data preparation\n",
    "    if counter == 0:\n",
    "        global col_header\n",
    "        col_header = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "    # base case\n",
    "    \n",
    "    if (pure_node(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        if(counter == max_depth):\n",
    "            return\n",
    "        print('Level ',counter)\n",
    "        iris_name,iris_count = (np.unique(data[:,-1], return_counts= True))        \n",
    "        for i in range(len(iris_name)):\n",
    "            print('Count of ',iris_name[i], ' = ' , iris_count[i])\n",
    "        \n",
    "        print('Current Entropy is =' ,calculate_entropy(data))\n",
    "        print('Reached leaf Node')\n",
    "        print()\n",
    "        \n",
    "    # recursive part\n",
    "    \n",
    "    else:\n",
    "        print('Level ',counter)\n",
    "        iris_name,iris_count = (np.unique(data[:,-1], return_counts= True))        \n",
    "        for i in range(len(iris_name)):\n",
    "            print('Count of ',iris_name[i], ' = ' , iris_count[i])\n",
    "        \n",
    "        print('Current Entropy is =' ,calculate_entropy(data))\n",
    "        \n",
    "        counter +=1\n",
    "        split = potential_split(data)\n",
    "        split_col , split_val , gain = find_best_split_using_gain_ratio(data , split)        \n",
    "        below , above = split_data(data,split_col , split_val)\n",
    "        # subtree\n",
    "        feature_name = col_header[split_col]\n",
    "        print('Splitting on feature' ,feature_name,'<=',split_val,'with gain ratio',gain )\n",
    "        print()\n",
    "        \n",
    "\n",
    "        decision_tree_steps(below,counter,min_samples,max_depth)\n",
    "        decision_tree_steps(above,counter,min_samples,max_depth)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "Count of  0.0  =  1\n",
      "Count of  1.0  =  3\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Splitting on feature x2 <= 0.5 with gain ratio 0.31127812445913283\n",
      "\n",
      "Level  1\n",
      "Count of  0.0  =  1\n",
      "Count of  1.0  =  1\n",
      "Current Entropy is = 1.0\n",
      "Splitting on feature x1 <= 0.5 with gain ratio 1.0\n",
      "\n",
      "Level  2\n",
      "Count of  0.0  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level  2\n",
      "Count of  1.0  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of  1.0  =  2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_steps(or_df,max_depth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_df = pd.DataFrame(or_data , columns = ['x1','x2','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2    y\n",
       "0  0.0  0.0  0.0\n",
       "1  0.0  1.0  1.0\n",
       "2  1.0  0.0  1.0\n",
       "3  1.0  1.0  1.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 <= 6\n",
      "Samples:11 \n"
     ]
    }
   ],
   "source": [
    "print(\"{} <= {}\\nSamples:{} \".format( 5,6 ,5+6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "print(\"ll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_print = []\n",
    "for i in tree:\n",
    "    list_print.append(i)\n",
    "    print(i)\n",
    "while(len(list_print)!=0):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pw <= 0.8\\ngain=1.0\\nsamples=130\\nvalue=[46 42 42] ': ['setosa',\n",
       "  {'pw <= 1.65\\ngain=0.7327835\\nsamples=84\\nvalue=[42 42] ': [{'pl <= 4.95\\ngain=0.6492629\\nsamples=44\\nvalue=[41  3] ': ['versicolor',\n",
       "      {'pw <= 1.55\\ngain=1.0\\nsamples=4\\nvalue=[1 3] ': ['virginica',\n",
       "        'versicolor']}]},\n",
       "    {'pl <= 4.85\\ngain=0.1866395\\nsamples=40\\nvalue=[ 1 39] ': [{'sw <= 3.1\\ngain=1.0\\nsamples=4\\nvalue=[1 3] ': ['virginica',\n",
       "        'versicolor']},\n",
       "      'virginica']}]}]}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
